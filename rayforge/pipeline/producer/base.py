from __future__ import annotations
from abc import ABC, abstractmethod
from typing import Optional, TYPE_CHECKING, Tuple, Dict, Any, Union
from enum import Enum, auto
from dataclasses import dataclass, asdict
import numpy as np
from ...core.ops import Ops

if TYPE_CHECKING:
    from ...core.workpiece import WorkPiece
    from ...machine.models.laser import Laser


class CutSide(Enum):
    """Defines which side of a path the laser cut should be on."""

    CENTERLINE = auto()
    """The center of the laser beam follows the path directly."""
    INSIDE = auto()
    """The final cut will be inside the original path."""
    OUTSIDE = auto()
    """The final cut will be outside the original path."""


class CoordinateSystem(Enum):
    """
    Defines the geometric coordinate space in which an Ops object was
    generated.
    """

    PIXEL_SPACE = auto()
    """
    An intermediate coordinate system for raster-based operations.

    - **Unit**: Pixels.
    - **Origin (0,0)**: Top-left corner of the source bitmap surface.
    - **Use**: Used by producers that trace raster images. The
      `source_dimensions` will be the width and height of the bitmap
      in pixels.
    """

    MILLIMETER_SPACE = auto()
    """
    The canonical coordinate system for all local vector geometry.

    This is the standard space for `workpiece.vectors` and any scalable ops
    generated by a producer.

    - **Unit**: Millimeters (mm).
    - **Origin (0,0)**: The bottom-left corner anchor of the workpiece.
    - **Orientation**: Y-axis pointing upwards (a standard Cartesian system).
    - **Use**: This is the contract for importers and for producers that
      output scalable vector geometry (`is_scalable=True`). The
      `source_dimensions` will be the width and height of the workpiece's
      "canvas" in millimeters.
    """


@dataclass
class PipelineArtifact:
    """
    A self-describing container for the output of an OpsProducer.
    """

    #: The generated machine operations.
    ops: Ops

    #: **The Behavioral Contract**: A flag indicating if the ops can be
    #: mathematically scaled.
    #: - True: The Ops are resolution-independent vectors. On resize, the
    #:   OpsGenerator can perform a cheap, real-time `ops.scale()` transform.
    #: - False: The Ops are resolution-dependent (e.g., raster lines). On
    #:   resize, the OpsGenerator must trigger an expensive, full regeneration.
    is_scalable: bool

    #: **The Geometric Contract**: An enum describing the coordinate space in
    #: which the ops were generated, primarily defining the origin.
    source_coordinate_system: CoordinateSystem

    #: The dimensions (width, height) of the "canvas" the ops were generated
    #: for, in units corresponding to the `source_coordinate_system`.
    #: (e.g., pixels for PIXEL_SPACE, mm for the others). This is essential
    #: for calculating relative scale factors.
    source_dimensions: Optional[Tuple[float, float]] = None

    #: The authoritative physical size (width, height) of the workpiece at the
    #: moment generation was triggered. This is crucial for scalable vector ops
    #: to ensure the correct canvas size is used, even if the workpiece object
    #: passed to the producer has had its own `.size` property modified.
    generation_size: Optional[Tuple[float, float]] = None

    def to_dict(self) -> Dict[str, Any]:
        """
        Serializes the artifact to a dictionary for inter-process transfer.
        """
        data = asdict(self)
        data["ops"] = self.ops.to_dict()
        data["source_coordinate_system"] = self.source_coordinate_system.name
        # Add a type field for the deserializer factory
        data["type"] = "vector"
        return data

    @classmethod
    def from_dict(cls, data: Dict[str, Any]) -> "PipelineArtifact":
        """Deserializes a dictionary back into a PipelineArtifact instance."""
        return cls(
            ops=Ops.from_dict(data["ops"]),
            is_scalable=data["is_scalable"],
            source_coordinate_system=CoordinateSystem[
                data["source_coordinate_system"]
            ],
            source_dimensions=tuple(data["source_dimensions"])
            if data.get("source_dimensions")
            else None,
            generation_size=tuple(data["generation_size"])
            if data.get("generation_size")
            else None,
        )


@dataclass
class HybridRasterArtifact:
    """
    A hybrid artifact for high-performance raster rendering.
    This is a standalone dataclass to avoid issues with field ordering
    during inheritance.
    """

    # Fields without default values must come first
    ops: Ops
    is_scalable: bool
    source_coordinate_system: CoordinateSystem
    power_texture_data: np.ndarray
    dimensions_mm: Tuple[float, float]
    position_mm: Tuple[float, float]

    # Fields with default values
    source_dimensions: Optional[Tuple[float, float]] = None
    generation_size: Optional[Tuple[float, float]] = None
    type: str = "hybrid_raster"

    def to_dict(self) -> Dict[str, Any]:
        """
        Serializes the artifact to a dictionary for inter-process transfer.
        """
        data = asdict(self)
        data["ops"] = self.ops.to_dict()
        data["source_coordinate_system"] = self.source_coordinate_system.name
        data["power_texture_data"] = self.power_texture_data.tolist()
        data["type"] = "hybrid_raster"
        return data

    @classmethod
    def from_dict(cls, data: Dict[str, Any]) -> "HybridRasterArtifact":
        """Deserializes a dict back into a HybridRasterArtifact instance."""
        return cls(
            ops=Ops.from_dict(data["ops"]),
            is_scalable=data["is_scalable"],
            source_coordinate_system=CoordinateSystem[
                data["source_coordinate_system"]
            ],
            power_texture_data=np.array(
                data["power_texture_data"], dtype=np.uint8
            ),
            dimensions_mm=tuple(data["dimensions_mm"]),
            position_mm=tuple(data["position_mm"]),
            source_dimensions=tuple(data["source_dimensions"])
            if data.get("source_dimensions") is not None
            else None,
            generation_size=tuple(data["generation_size"])
            if data.get("generation_size")
            else None,
        )


def deserialize_artifact(
    data: Dict[str, Any],
) -> Union[PipelineArtifact, HybridRasterArtifact]:
    """
    Factory function that deserializes a dictionary into the correct
    artifact type based on the 'type' field.

    Args:
        data: A dictionary containing the serialized artifact data.

    Returns:
        Either a PipelineArtifact or HybridRasterArtifact instance.
    """
    artifact_type = data.get("type")

    if artifact_type == "hybrid_raster":
        return HybridRasterArtifact.from_dict(data)
    else:
        # Default to PipelineArtifact for "vector" type or if type is missing
        # for backward compatibility.
        return PipelineArtifact.from_dict(data)


class OpsProducer(ABC):
    """
    Given a Cairo surface, an OpsProducer outputs an Ops object.
    Examples may include:

    - Tracing a bitmap to produce a path (Ops object).
    - Reading vector data from an image to turn it into Ops.
    """

    @abstractmethod
    def run(
        self,
        laser: "Laser",
        surface,
        pixels_per_mm,
        *,
        workpiece: "Optional[WorkPiece]" = None,
        settings: Optional[Dict[str, Any]] = None,
        y_offset_mm: float = 0.0,
    ) -> Union[PipelineArtifact, HybridRasterArtifact]:
        pass

    def is_vector_producer(self) -> bool:
        """
        Specifies the generation strategy for the producer.

        - True: Use the vector/full-render path. The producer can handle
          vector inputs directly, or it traces a single, fully-rendered
          raster image.
        - False: Use the chunked raster path. The producer requires the
          input to be rendered and fed to it in horizontal strips.

        This controls the *process* of generation, while the artifact's
        `is_scalable` flag controls the caching behavior of the *product*.
        """
        return True

    @property
    def requires_full_render(self) -> bool:
        """
        Returns True if a producer requires the entire workpiece to be
        rendered into a single surface, even though its output is scalable.
        This is essential for algorithms that need a global view of the image,
        like hulling, and forces the pipeline to provide a raster input.
        """
        return False

    @property
    def supports_kerf(self) -> bool:
        """
        Returns True if this producer's logic can apply kerf compensation.
        This is typically True for vector-based producers.
        """
        return False

    @property
    def supports_cut_speed(self) -> bool:
        """
        Returns True if this producer's logic supports a fixed cut speed.
        Producers that have variable speed logic may not.
        """
        return True

    @property
    def supports_power(self) -> bool:
        """
        Returns True if this producer's logic supports a fixed power setting.
        Producers that have variable power logic may not.
        """
        return True

    def to_dict(self) -> dict:
        """
        Serializes the producer configuration to a dictionary.

        This dictionary can be used with `OpsProducer.from_dict` to
        recreate the producer instance.
        """
        return {
            "type": self.__class__.__name__,
            "params": {},  # Default for stateless producers
        }

    @classmethod
    def from_dict(cls, data: dict) -> "OpsProducer":
        """
        Deserializes a producer from a dictionary.

        This is a factory method that looks up the producer class by its
        name from the central registry and dispatches to the class's own
        `from_dict` method.
        """
        from . import producer_by_name

        producer_type = data.get("type")
        if not producer_type:
            raise ValueError("Input dictionary must contain a 'type' key.")

        ProducerClass = producer_by_name.get(producer_type)
        if not ProducerClass:
            raise ValueError(f"Unknown producer type: '{producer_type}'")

        # Dispatch to the specific class's from_dict method
        return ProducerClass.from_dict(data)
